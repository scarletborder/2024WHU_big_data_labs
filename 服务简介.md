factory: 数据生产者,可以横向拓展为很多个数据生产者

etcd: 服务发现,factory在这里找到自己可用的kafka消息队列

kafka: 消息队列,将factory来的消息传送给hdfs

hdfs: 存放大量的原始数据,每一个不同的数据节点订阅一个不同的kafka topic

user: 使用hadoop里的数据进行处理,并将结果存放在mongodb中

mongodb: 存放处理后非结构化的数据

panel: 最终端用户,观看mongodb中处理后的数据结果


factory : hdfs_hanlder其实是一个多对少,因此factory需要通过服务发现选择一个负载最少的kafka作为将来一段时间的
数据传送topic.
每个hdfs datanode 会有一个 hdfs_handler ,其会监听一个固定的kafka topic